\documentclass[12pt, class=report, crop=false]{standalone}
\usepackage{ba_thesis}

\begin{document}

\chapter{Numerical Methods Project: The Boris Push in PIC Codes}%
\section{The Relevant Equations}

Particle-in-cell codes are nowadays the most popular popular tool for simulating plasma systems. One of the best references for what they are, how they work and how reliable the results are is the book by~\cite{birdsallPlasmaPhysicsComputer1995}, which describes the main numerical methods used and some of their properties. However, Particle-in-cell codes have evolved greatly in the last two decades and new techniques and optimizations have been produced and even put in practice. Even so, with the exception of quasistatic codes, they are still involved in solving the same physical equations. As such, it is useful for anyone interested in working with such software to know and understand the principles behind.

In general, PIC codes have four main componets:
\begin{enumerate}
  \item A Maxwell solver which propagates the Maxwell equations (which are relativistic invariant by themselves) in time and space on the grid
  \begin{subequations}
    \begin{align}
    \div{\vb{E}} & = \frac{\rho}{\varepsilon_0} \\
    \div{\vb{B}} & = 0 \\
    \curl{\vb{E}} & = - \pdv{\vb{B}}{t} \\
    \curl{\vb{B}} & = \mu_0 \vb{j} + \frac{1}{c^2} \pdv{\vb{E}}{t} \,;
    \end{align}
  \end{subequations}
  \item A field gatherer that interpolates the electromagnetic field at the particle positions on the grid;
  \item A particle pusher that advances the positions and velocities of each particle under the action of the Lorentz force (which we will write in its relativistic form)
  \begin{subequations}
    \begin{align}
      \label{eq:NL}
      \dv{\vb{p_\alpha}}{t} = q_\alpha \left(\vb{E}+\frac{\vb{p_\alpha}}{m_\alpha \gamma_\alpha} \cp \vb{B} \right)\\
      \gamma_\alpha = \sqrt{1+\left(\frac{\vb{p_\alpha}}{m_\alpha c}\right)^2}\,,
    \end{align}
  \end{subequations}
  where \(\alpha\) indexes each particle;
  \item Acurrent and charge depositor which computes the current and charge densities on the grid by interpolating the particle distributions.
\end{enumerate}

The main appeal of this approach is its self-consistency. That is, the total fields used are both those that are part of the electromagnetic waves that are introduced in the system (in general laser beams) and those generated by the charged particles that compose the plasma. As such we also include the long range Coulombian interaction between particles. The short range interaction, namely collisions between particles, is by default neglected since we usually simulate rarefied plasmas, but many codes now come with additional routines that include these processes. Additional routines are now developed with the advent of the high intensity laser technologies because at the corresponding energies reached by the particles quantum electrodynamical effects become relevant. Although there are quite a few PIC codes that include QED routines, there is still a long way untill these algorithms reach the efficiency and stability that of those four main ones described above. As such, the implementation of QED effects in numerical plasma simulations is currently a hot research topic.

It is mandatory to mention that while the four steps above outline a microscopic model, PIC simulations are not completely microscopic due to technological limitations regarding computing power. Instead of working with one virtual particle for one real particle, it is customary to use macro-particles. A macro-particle represents many particles of the same species (from \(10^6\) to \(10^11\) depending on the propeties of our plasma) moving colectively. These particles are obviously not localized at a single point, but rather they have a shape function attached to them to make the derivation of currents and charge densities more consistent. For a long time the use of macro-particles was not supported by argument and was a source of criticism towards PIC methods. The defense was built only on the excuse of that the simulations give very accurate statistical results. Things are different nowadays. We can now explain (quite easily in fact) that the macro-particles themselves can be interpreted a statistical ensamble of real particles. The secret lies in the Vlasov equation.

\subsection{The Connection with the Vlasov Equation}

Let us revisit the Vlasov equation, which we derived in~\cref{sec:Vlasov}

\begin{equation}
  \pdv{\rho}{t} + \vb{f}\vdot\pdv{\rho}{\vb{p}} + \vb{v}\vdot\pdv{\rho}{\vb{r}} = 0\,,
\end{equation}
where \(\rho\) was the distribution function that describes the entire system of particles, \(\vb{p}=(\vb{p_1}, \vb{p_2},\dots )\) and \(\vb{v}=(\vb{v_1}, \vb{v_2},\dots )\), \(\vb{r}=(\vb{r_1}, \vb{r_2},\dots )\) the momenta, the velocities, and the positions of the particles, and \(\vb{f}=(\vb{f_1}, \vb{f_2},\dots )\) the forces acting on each particle.

The main argument in the following discussion is a relativistic upgrade of the one in~\cite{liuHighPowerLaserPlasmaInteraction2020}. For consistency with the equations we outlined for the PIC method, I rewrite this equation in its relativistic form and considering all forces to be of the Lorentz type

\begin{equation}
  \pdv{\rho}{t} + \sum_\alpha \left[ q_\alpha \left(\vb{E_\alpha}+\frac{\vb{p_\alpha}}{m_\alpha \gamma_\alpha} \cp \vb{B_\alpha} \right) \pdv{\rho}{\vb{p_\alpha}} +  \frac{\vb{p_\alpha}}{m_\alpha \gamma_\alpha} \pdv{\rho}{\vb{r_\alpha}}\right] =0\,,
\end{equation}
where \(\alpha\) indexes all the particles in the system and the fields \(E_\alpha\) and \(B_\alpha\) are to be computed at the position of particle \(\alpha\).

The key insight now is that imposing that the particles move under the Newton-Lorentz~\cref{eq:NL} implies having a stationary solution for the distribution function. That is, the equations

\begin{subequations}
  \label{eq:boris1}
  \begin{align}
    \dv{\vb{p_\alpha}}{t} = q_\alpha \left(\vb{E}+\frac{\vb{p_\alpha}}{m_\alpha \gamma_\alpha} \cp \vb{B} \right)\\
    \dv{\vb{r_\alpha}}{t} = \frac{\vb{p_\alpha}}{m_\alpha \gamma_\alpha}\,,
  \end{align}
\end{subequations}
reduce the Vlasov equation as follows

\begin{equation}
  \pdv{\rho}{t} + \sum_\alpha \left( \pdv{\rho}{\vb{p_\alpha}}\dv{\vb{p_\alpha}}{t} + \pdv{\rho}{\vb{r_\alpha}} \dv{\vb{r_\alpha}}{t} \right) = \dv{\rho}{t} = 0 \,.
\end{equation}

Of course this is not an equivalency. While~\cref{eq:boris1} implies that the distribution function of the entire system is stationary, the reverse is not true, unless we do a rough approximation and suppose that the total distribution can be separated in a sum of independent single particle distribution functions. By employing this latter approximation we would unavoidably neglect some intrinsic interactions that take place in our system. Nonetheless, this problem does not affect the validity of our Particle-in-cell method. The thing is that while~\cref{eq:boris1} doesn't describe all the complete stationary solution of the Vlasov equation, it still describes at least one particular stationary solution. Working with superparticles is like studying the evolution of an ensable of these solutions. Thus, by including a relevant (yet not large enough to give unreasonable simulation times) number of superparticles we obtain a statistically realistic solution. Some even call PIC a Monte-Carlo method because of this.

The reverse approach is used in numerical studies of plasma physics using Vlasov codes (VC). These approaches simply try to solve the Vlasov equation as it is in order to obtain exact solutions (exact up to numerical errors). If one has the total distribution function then every statistical piece of information about the system is known. Some basics about how this can be achieved and computational optimization can be found in~\cite{silinVlasovcodeSimulationsCollisionless}. However, directly solving such a big solution with a number of variables proportional to the real number of particles in the system takes a lot of time if we try to simulate realistically sized systems.

An approach based on the splitting of the distribution function is not completely flawed. One can try to get closer to reality by using a better approximation by expanding the total distribution in a series that contains single-particle terms, two-particle terms, and so on. While it is true that this improves the solutions greatly, the cost in computation time is equally great and much refinement would have to be done.

The presentation so far should not give the reader the impression that PIC is the supperior approach. In fact, numerical heating is a common problem of PIC codes and the stability conditions for the simulations are quite restrictive, which together with the computational limitations reduce the amount of experiments you can run. An easy to follow rought sketch of the trade off between PIC and VC and a discussion on when is one better than the other is found in~\cite{bertrandVlasovModelsLaser2005}.

\section{Methods used in Particle-in-cell simulations}
\subsection{The Boris Push}

It is time now to tackle the first method in the context of Particle-in-cell simulations. It is discussed in~\cite{birdsallPlasmaPhysicsComputer1995}, there are different ways to implement particles pushers, either by partially separating the action of the electric and magmetic fields~(\cite{bunemanTimereversibleDifferenceProcedures1967}), or by separating them completely~(\cite{borisRelativisticPlasmaSimulation1970}). Along the years, even more alternatives have surfaced. A nice up-to-date review of the currently relevant relativistic schemes for particle dynamics in electromagnetic fields is~\cite{ripperdaComprehensiveComparisonRelativistic2018}. In this section we will present and analyze the Boris push, since it is widely implemented in the currently available PIC codes. The popularity of this specific scheme stems from its practical performance. Since its initial proposal, the Boris push was observed to have good accuracy over long integration times in simulations. The explanation for why it works so well was given only recently in~\cite{qinWhyBorisAlgorithm2013}. They studied only the properties of the non-relativistic scheme. Because of this, we will also start with the classical case, wich is simpler, in order to gain some intuition.

\subsubsection{Classical Boris Push}

We aim to solve the followwing equations

\begin{subequations}
  \begin{align}
    \dv{\vb{r}}{t} = \vb{v}\\
    \dv{\vb{v}}{t} = \frac{q}{m} \left(\vb{E} + \vb{v}\cp \vb{B}\right)\,.
  \end{align}
\end{subequations}
We will employ the Störmer-Verlet method

\begin{subequations}
  \begin{align}
    \label{eq:borisp1}
    \vb{r_{n+1}} = \vb{r_n} + \vb{v_{n+\frac{1}{2}}} \Delta t\\
    \label{eq:borisp2}
    \vb{v_{n+\frac{1}{2}}} = \vb{v_n} +\frac{q}{m} \frac{\Delta t}{2} \left[\vb{E} + \vb{v} \cp \vb{B} \right]_{\vb{r} = \vb{r_n}}\\
    \vb{v_{n}} = \vb{v_{n+\frac{1}{2}}} +\frac{q}{m} \frac{\Delta t}{2} \left[\vb{E} + \vb{v} \cp \vb{B} \right]_{\vb{r} = \vb{r_{n+1}}}\,.
  \end{align}
\end{subequations}
In order to find a good evaluation for the quantities enclosed in square brackets we need to play around a bit with these equations. By lowering the third one by one step and replacing in the second we get

\begin{equation}
  \frac{\vb{v_{n+\frac{1}{2}}} - \vb{v_{n-\frac{1}{2}}} }{\Delta t} = \frac{q}{m} \left[\vb{E} + \vb{v} \cp \vb{B} \right]_{\vb{r} = \vb{r_n}}\,.
\end{equation}
Let us now take~\cref{eq:borisp1} at two consecutive steps

\begin{subequations}
  \begin{align}
    \vb{r_{n}} = \vb{r_{n-1}} + \vb{v_{n-\frac{1}{2}}} \Delta t\\
    \vb{r_{n+1}} = \vb{r_n} + \vb{v_{n+\frac{1}{2}}} \Delta t\,
  \end{align}
\end{subequations}
and add them to obtain

\begin{equation}
  \frac{\vb{r_{n+1}} - \vb{r_{n-1}}}{\Delta} = \frac{\vb{v_{n+\frac{1}{2}}} + \vb{v_{n-\frac{1}{2}}}}{2}\,,
\end{equation}
which is we will use as an approximation for the velocity at \(\vb{r} = \vb{r_n}\). We finally reach the following scheme

\begin{subequations}
\label{eq:actual-boris1}
  \begin{align}
    \label{eq:actual-boris11}
    \frac{\vb{r_{n+1}} - \vb{r_n}}{\Delta t} = \vb{v_{n+\frac{1}{2}}}\\
    \label{eq:actual-boris12}
    \frac{\vb{v_{n+\frac{1}{2}}} - \vb{v_{n-\frac{1}{2}}} }{\Delta t} = \frac{q}{m} \left(\vb{E_n} + \frac{\vb{v_{n+\frac{1}{2}}} + \vb{v_{n-\frac{1}{2}}}}{2} \cp \vb{B_n} \right)\,.
  \end{align}
\end{subequations}
This is the Boris push, but it is not yet the final algorithm. In order to be able to implement this scheme in an actual code, we need a way to separate \(\vb{v_{n+\frac{1}{2}}}\) and \(\vb{v_{n-\frac{1}{2}}}\) from the second equation. There are many equivalent ways to do so, but Boris originally came up with a method to separate the action of the electric and magnetic fields by employing the following three equations

\begin{subequations}
\label{eq:actual-boris2}
  \begin{align}
    \label{eq:actual-boris21}
    \vb{v^-} = \vb{v_{n-\frac{1}{2}}} + \frac{q}{m} \vb{E_n} \frac{\Delta t}{2}\\
    \label{eq:actual-boris22}
    \frac{\vb{v^+} - \vb{v^-} }{\Delta t} = \frac{q}{m} \frac{\vb{v^+} + \vb{v^-} }{2} \cp \vb{B_n}\\
    \label{eq:actual-boris23}
    \vb{v_{n+\frac{1}{2}}} = \vb{v^+} + \frac{q}{m} \vb{E_n} \frac{\Delta t}{2}\,,
  \end{align}
\end{subequations}
where the second step rewritten in the following way:

\begin{subequations}
\label{eq:actual-boris3}
  \begin{align}
    \vb{v^+} = \vb{v^-} + (\vb{v^-} + \vb{v^-} \cp \vb{t}) \cp \vb{s}\\
    \vb{t} = \frac{q}{2m} \vb{B_n} \Delta t\\
    \vb{s} = \frac{2}{1+t^2} \vb{t}\,.
  \end{align}
\end{subequations}
The full classical Boris push code recipe is described by~\cref{eq:actual-boris11,eq:actual-boris21,eq:actual-boris3,eq:actual-boris23} put together. Note that we basically work only with mid-step velocities. But we can always recover the actual velocities from~\cref{eq:borisp2} like this

\begin{equation}
  \vb{v_n} = \vb{v_{n+\frac{1}{2}}} - \frac{q}{m} \frac{\Delta t}{2} \left(\vb{E_n} + \frac{\vb{v_{n+\frac{1}{2}}} + \vb{v_{n-\frac{1}{2}}}}{2} \cp \vb{B_n} \right)\,.
\end{equation}
Such an equation is useful in order to get the initial conditions for the mid-step velocities from the initial conditions given for the velocity.

We introduced~\cref{eq:actual-boris2,eq:actual-boris3} out of nowhere, but it is quite straightforward to see that by eliminating \(v^-\) and \(v^+\) we simply recover~\cref{eq:actual-boris12}. This is just a convenient way to write for a machine to understand, but is simply a reorganization of the \cref{eq:actual-boris12}. It does not influence numerical properties. That is, all the nunerical properties of the algorithm lie in \cref{eq:actual-boris1}. There is a geometrical interpretation to the break up described by~\cref{eq:actual-boris2}. \(v^-\) and \(v^+\) give the drift motion due to electric field, \cref{eq:actual-boris2} described a rotation under the effect of a constant magnetic field. For a more in depth description with images to help visualization I recommend the Master Thesis of~\cite{micluta-campeanuLaserWakefieldAcceleration2019}.

\subsubsection{Relativistic Boris Push}

The relativistic version should discretize~\cref{eq:NL} in the same way we presented so far. If we make the notation \(\vb{u} = \gamma \vb{v}\), the equations of the algorithm are now simply

\begin{subequations}
  \begin{align}
    \frac{\vb{r_{n+1}} - \vb{r_n}}{\Delta t} = \frac{\vb{u_{n+\frac{1}{2}}}}{\gamma_{n+\frac{1}{2}}},\; \gamma_{n+\frac{1}{2}} =
    \sqrt{1+\left(\frac{u_{n+\frac{1}{2}}}{c}\right)^2}\\
    \vb{u^-} = \vb{u_{n-\frac{1}{2}}} + \frac{q}{m} \vb{E_n} \frac{\Delta t}{2}\\
    \vb{u^+} = \vb{u^-} + (\vb{u^-} + \vb{u^-} \cp \vb{t}) \cp \vb{s},\;
    \vb{t} = \frac{q}{2m \gamma_n} \vb{B_n} \Delta t,\; \vb{s} = \frac{2}{1+t^2} \vb{t}\\
    \gamma_n = \sqrt{1+\left(\frac{\vb{u}^-}{c}\right)^2} = \sqrt{1+\left(\frac{\vb{u}^+}{c}\right)^2}\\
    \vb{u_{n+\frac{1}{2}}} = \vb{u^+} + \frac{q}{m} \vb{E_n} \frac{\Delta t}{2}\,.
  \end{align}
\end{subequations}

\subsection{Symplecticity and Volume Conservation Theory}

In terms of accuracy, the Boris push remains at its core a twist on the Störmer-Verlet method, so it an be shown that it is a second order scheme. But there are things that are not inherited this way. We already saw that the Störmer-Verlet and leapfrog integrators are very similar. It a known fact that the leapfrog scheme is one of the simplest symplectic and as such it has outstanding conservation properties. But we can not expect the Boris push to be the same. The thing that throws everything off is the dependence on velocity that we have introduced in the expression of the force. Even so, the Boris push still has a strength in that it is volume preserving. It is also important to mention that it conserves energy exactly in the absence of the electric field. This may not seem that great in itself, since the electric field is never vanishing in practical simulations, but it was a hint towards the idea that it might be volume preserving. In what follows we will delve a bit into the concept of symplecticity and see how we can find out if a scheme has this property. Of course, our example for this theory will be the Boris push algorithm.

In order to give a concrete mathematical definition for simplecticity we have to define a handy tool first, as presented on p. 164 in~\cite{arnoldMathematicalMethodsClassical1997}.

\begin{definition}
  Let \(M^{2n}\), \(n\in \mathbb{N}\), be a differentiable manifold with an even number of dimensions (this is general, so we can use any such manifold, but for our numerical methods related endeavours we really only need to talk about \(\mathbb{R}^{2n}\)). \textbf{An exterior form of degree two} (or a \textbf{2-form}) on this manifold is a map \(\omega_2 : M^n \cp M^n \rightarrow M\) that is bilinear and skew symmetric:

  \begin{align*}
  \omega_2 (\lambda_1 \vb*{\xi_1} + \lambda_2 \vb*{\xi_2}, \vb*{\xi_3}) &=
  \lambda_1 \omega_2 (\vb*{\xi_1}, \vb*{\xi_3}) + \lambda_2 \omega_2 (\vb*{\xi_2}, \vb*{\xi_3}) \\
  \omega_2 (\vb*{\xi_1},\vb*{\xi_2}) &= -\omega_2 (\vb*{\xi_2}, \vb*{\xi_1})\,,
  \end{align*}
  \(\forall \lambda_1,\;\lambda_2 \in M, \vb*{\xi_1},\;\vb*{\xi_2},\;\vb*{\xi_3} \in M^n\).
  If we also have the extra property that \(\omega_2 (\vb*{\xi_1},\vb*{\xi_2}) = 0,\;\forall \vb*{\xi_2}\) implies \(\vb*{\xi_1}=0\) we say that the 2-form is non-degenerate.
\end{definition}

Note that the even dimensionality of our manifold is an important aspect of the definition. It is also important to remark that all the concepts we discuss here in this chapter play an important role in analytical mechanics, since the phase space is always even dimensional.

In a two dimensional space, the determinant of the matrix obtained by the augmentation of two vectors gives the area of the paralelogram described by the two vectors~(\cite{golombProofWordsDeterminant1985}). The determinant in this context is also a basic example of a 2-form. This is not a mere coincidence. In general, a differential 2-form at a point (an exterior 2-form on the tangent space at that point) computes a local oriented differential area there. This observation is in a way valid for any k-form, but we are not interested in developing too much geometry in this text.

I mentioned the tangent space. This concept is actually necessary to understand in order to move forward, so let us present a short definition adapted to our interests~(\cite{weissteinTangentSpace}):

\begin{definition}
  Let \(\vb*{x}\) be a point in our manifold \(M^{2n}\). If we attach a copy of \(\mathbb{R}^{2n}\) tangential to \(M^{2n}\) at \(\vb{x}\) we obtain a structure called \textbf{the tangent space} of \(M^{2n}\) at \(\vb*{x}\) and we denote it by \(T_{\vb*{x}}M\).
\end{definition}

As any concept in differential geometry, it is easy to understand it in spaces with a small number of dimensions. The simplest to visualize in my opinions is the 2D surface of a sphere. If we choose any point on the sphere and stick at that point an infinite plane we obtain the tangent space at that point. The idea of the tangent space is something that people are actually used with from calculus. Say we have a curve on our manifold that passes through \(\vb{x}\). The derivative of the curve at \(\vb{x}\) is a vector in the tangent space. Coming back to our 2D example, on a shpere surface the derivative of a curve on it at a point is tangent to the sphere, so basically an stright arrow tangent to the sphere at that point. But clearly that arrow is not \textit{on} the sphere. It is on the tangent plane part of the tangent space. This is really an extension to the idea in calculus that the derrivative gives the slope of the function at a point.

\begin{definition}
  A symplectic form on \(M^{2n}\) is a smooth closed non-degenerate 2-form \(\omega_2\) on \(M^{2n}\) such that the alternating bilinear map \(\omega_2^{\vb*{x}} : T_{\vb*{x}}M^{2n} \cp T_{\vb*{x}}M^{2n} \rightarrow \mathbb{R}\) defined by the expression of \(\omega_2\) at every point \(\vb*{x} \in M^{2n}\) is also non-degenerate.
\end{definition}

This may seem quite an abstract and hard to digest idea, so let us dismiss it with a particularization relevant for our problem at hand. If our manifold is \(\mathbb{R}^{2n}\) then any 2-form \(\omega_2 : \mathbb{R}^{2n} \cp \mathbb{R}^{2n} \rightarrow \mathbb{R}\) is symplectic simply if \(\omega_2 (\vb{x},\vb{x}) = 0\) for any \(\vb{x}\) in \(\mathbb{R}^{n}\)~(\cite{weissteinSymplecticForm}).

\begin{definition}
  A linear map \(A: M^{n} \to M^{n}\) is called
  \emph{symplectic} if there exists a symplectic form \(\omega_2: M^n \cp M^n \rightarrow M\)
  such that
  \(
  \omega_2 (A\vb*{\xi}, A\vb*{\eta}) = \omega_2 (\vb*{\xi},\vb*{\eta})\,,\
  \forall \vb*{\xi}, \vb*{\eta} \in M^{n}\,.
  \)
\end{definition}

For real manifolds we can reformulate this in the following way:

\begin{definition*}
  A linear map \(A: \mathbb{R}^{n} \to \mathbb{R}^{n}\) is called
  \emph{symplectic} if there exists a 2-form \(\omega_2\) on \(\mathbb{R}^{2n}\) with \(\omega_2 (\vb*{x},\vb*{x}) = 0,\;\forall \vb*{x} \in \mathbb{R}^{n}\)
  such that
  \(
  \omega_2 (A\vb*{\xi}, A\vb*{\eta}) = \omega_2 (\vb*{\xi},\vb*{\eta})\,,\
  \forall \vb*{\xi}, \vb*{\eta} \in \mathbb{R}^{n}\,.
  \)
\end{definition*}

An equivalent condition can be given in matrix form

\begin{equation}
\label{cond:symplectic}
  A^T J A = J\,,
\end{equation}
where \(J = \begin{bmatrix}
  0_n & I_n \\
  -I_n & 0_n
\end{bmatrix}\) and \(I_n\) is the \(n\)-dimensional unitary matrix (remark: \(J^{-1} = -J\)).

% offer proof

Taking the determinant of each side in the identity~\ref{cond:symplectic} results that the determinant of the matrix \(A\) is \(\pm\)1. We can do better. It is always 1. The proof usually involves using the Pfaffian, but it is possible to avoid this~(\cite{rimElementaryProofThat2018}). Let us make use of the fact that \(A^T A\) is symmetric (note that \((A^T A)^T = A^T (A^T)^T = A^T A\)). Since \(\det(A) \neq 0\), \(A\) is invertible, so \(A^T A\) is also positive definite.

As a side note we should mention that the simple fact that we found that \(A\) is invertible lets us compute the inverse. Indeed,

\begin{equation}
\label{inv-sympl-matix}
  A^T J A = J \Rightarrow A^T J A A^{-1} = A^T J = J A^{-1} \Rightarrow A^{-1} = J^{-1} A^T J\,.
\end{equation}

We will do a little trick now. \(A^T A\) is both symmetric and positive definite. This means that its eigenvalues are real and positive. If \(\vb{v}\) is an eigenvector of \(A^T A\) and \(\lambda\) the corresponding eigenvalue. Then \((A^T A + I_{2n}) \vb{v} = (\lambda + 1)\vb{v}\). This means that the eigenvalues of \(A^T A + I_{2n}\) are greater than one. Since the determinant is the product of eigenvalues, we have

\begin{equation*}
  \det(A^T A + I_{2n}) > 1\,.
\end{equation*}

We can extract an \(A^T\) now

\begin{equation*}
  A^T A +I_n = A^T (A+ (A^T)^{-1}) = A^T (A + J^{-1} A J)\,,
\end{equation*}
such that

\begin{equation}
  \label{ineq:det}
  0 < 1 < \det(A) \det(A + J^{-1} A J)\,.
\end{equation}
Let us write our matrix as \( A=
\begin{bmatrix}
  a & b\\
  c & d
\end{bmatrix}
\), with \(a,\; b,\; c,\; d \in \mathbb{R}^n\). Now

\begin{equation*}
  A + J^{-1} A J =
  \begin{bmatrix}
    a & b\\
    c & d
  \end{bmatrix} +
  \begin{bmatrix}
    0_n & -I_n \\
    I_n & 0_n
  \end{bmatrix}
  \begin{bmatrix}
    a & b\\
    c & d
  \end{bmatrix}
  \begin{bmatrix}
    0_n & I_n \\
    -I_n & 0_n
  \end{bmatrix} =
\end{equation*}

\begin{equation*}
  =
  \begin{bmatrix}
    a & b\\
    c & d
  \end{bmatrix} +
  \begin{bmatrix}
    0_n & -I_n \\
    I_n & 0_n
  \end{bmatrix}
  \begin{bmatrix}
    -b & a\\
    -d & c
  \end{bmatrix} =
\end{equation*}

\begin{equation*}
  =
  \begin{bmatrix}
    a & b\\
    c & d
  \end{bmatrix} +
  \begin{bmatrix}
    d & -c \\
    -b & a
  \end{bmatrix} =
  \begin{bmatrix}
    a+d & b-c\\
    -(b-c) & a+d
  \end{bmatrix}\,.
\end{equation*}
Denoting \(B\equiv a+ d\) and \(C\equiv b-c\) we can make use of the following decomposition

\begin{equation*}
  A + J^{-1} A J =
  \begin{bmatrix}
    \frac{1}{\sqrt{2}} I_n & \frac{1}{\sqrt{2}} I_n\\
    \frac{\ii}{\sqrt{2}} I_n & -\frac{\ii}{\sqrt{2}} I_n
  \end{bmatrix}
  \begin{bmatrix}
    B+ \ii C & 0_n\\
    0_n & B-\ii C
  \end{bmatrix}
  \begin{bmatrix}
    \frac{1}{\sqrt{2}} I_n & \frac{1}{\sqrt{2}} I_n\\
    \frac{\ii}{\sqrt{2}} I_n & -\frac{\ii}{\sqrt{2}} I_n
  \end{bmatrix}^T\,,
\end{equation*}
Which we can use in~\cref{ineq:det}

\begin{equation*}
  0 < \det(A) \det(B+\ii C) \det(B-\ii C) = \det(A) \abs{\det(B+\ii C)}\,,
\end{equation*}
which concludes that \(\det(A)>0\).

Together with the fact \(\det(A)\) can only take the values \(\pm\)1 this completes the proof that \textbf{the determinant of the associated matrix of a symplectic linear map is 1}.

This is the complete set of mathematical definitions and nomenclature that develop the concept of symplectic maps. But a question still remains: what is a symplectic map \textit{really}? Well, it is a generalization of area-preservance (the image of a subset of our manifold through an area-preserving map has the same volume as the subset itself; in this thesis we use volume and area preservence interchangably). In practice it is useful to use the following result in order to decide if this property holds: \textbf{a linear map is area-preserving if and only if its associated matrix has the determinant equal to 1}. The proof is omitted since it can be easily found in many places across the internet (also, note that area-preservance is a necessary, but not sufficient condition for symplecticity, considering our previous discussion). Now, looking at phase space, if a linear map is symplectic then, informally, the sum of areas projected on the planes \((\vb{q_i},\vb{p_i}),\;i = \overline{1,n}\) is conserved~(\cite{weissteinSymplecticMap}), so we can have a lot more quatities conserved. Symplecticity, in this perspective, could be related to generalized angular momenta conservation. Indeed, it has been shown that there are symplectic algorithms (Störmer-Verlet schemese, or modifications of it) which conserve angular momentum exactly~(\cite{zhangSymplecticIntegratorsConservation1995}). We must mention that energy conservation is better than symplecticity. In general energy conservation sits above symplecticity, which sits above area-preservance. This may not seem that obvious, since all these three conservation properties are identical in two dimensions and the 2D phase space (1D system) is pretty much the only one our mind can really visualize (a 2D system would have a 4D phase space). The advantage of symplectic or at least volume preserving algorithms is that the energy drift is not diverging and is quite small.

We still have to make one more step in order to study the properties of the Boris push. The problem is that the map that describes this scheme is not linear, so we can not directly use what we presented so far. We simply have to define simplecticity for a larger class of mappings (p.~183~\cite{hairerGeometricNumericalIntegration2006}).

\begin{definition}
  A map \(f:\mathbb{R}^{2n}\rightarrow \mathbb{R}^{2n}\) is symplectic if its Jacobian matrix is symplectic.
\end{definition}

In a similar manner we can define a area-preservance for a wider selection of maps.

\begin{definition}
  A map \(f:\mathbb{R}^{2n}\rightarrow \mathbb{R}^{2n}\) is area-preserving if the determinant of its Jacobian matrix is equal to 1.
\end{definition}

No matter how we look at all these things, what actually do every time is to check the condition~\ref{cond:symplectic} for a matrix. We usually call the matrices that solve this identity symplectic. It turns out that for a fixed \(n\) the set of all the symplectic matrices form a group (the identity element is \(I_{2n}\), The inverse is given by \cref{inv-sympl-matix}, proving closure and associativity is trivial). In fact, it is a Lie group commonly denoted as \(Sp(2n,\mathbb{R})\). The tangent space at the identity element defines its Lie algebra.

\subsection{Conservation Properties of the Boris push}

In order to check the conservation properties of the Boris push we need to find a way to express~\cref{eq:actual-boris1} as a matrix equation between the position and velocity at a step and those at the next step. For this we will use the hat map (while it is connected to group theory, we introduce it just as a tool).

\begin{definition}
  For a vector \(\vb*{v} = (v_1, v_2,v_3) \in \mathbb{R}^3\) the corresponding hat map is the matrix
  \[
  \hat{\vb*{v}} =
  \begin{bmatrix}
    0 & -v_3 & v_2 \\
    v_3 & 0 & -v_1\\
    -v_2 & v_1 & 0
  \end{bmatrix}\,.
  \]
\end{definition}

\begin{proposition}
  The vector product of two vectors \(\vb*{u}\) and \(\vb*{v}\) can be expressed with the help of the hat map in the following way
  \[
    \vb*{u}\cp \vb*{v} = \hat{\vb*{u}} \vb*{v}\,.
  \]
\end{proposition}

With this preparation we can extract from the Boris push equations

\begin{subequations}
  \begin{align}
    \frac{\vb{r_{n+1}} - \vb{r_n}}{\Delta t} = \vb{v_{n+\frac{1}{2}}}\\
    \frac{\vb{v_{n+\frac{1}{2}}} - \vb{v_{n-\frac{1}{2}}} }{\Delta t} = \frac{q}{m} \left(\vb{E_n} + \frac{\vb{v_{n+\frac{1}{2}}} + \vb{v_{n-\frac{1}{2}}}}{2} \cp \vb{B_n} \right)\,
  \end{align}
\end{subequations}
the step update into a more convenient matrix notation

\begin{subequations}
  \begin{align}
    \vb{r_{n+1}} = \vb{r_n} + \Delta t \vb{v_{n+\frac{1}{2}}}\\
    \label{eq:boris-matrix-2}
    \left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right) \vb{v_{n+\frac{1}{2}}} = \left( I_3 - \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right) \vb{v_{n-\frac{1}{2}}} + \frac{q\Delta t}{m} \vb{E_n}\,,
  \end{align}
\end{subequations}
where \(I_3\) is the three dimensional identity matrix and
\[
\vb{\hat{B}_n} = \begin{bmatrix}
  0 & -B_n^3 & B_n^2\\
  B_n^3 & 0 & -B_n^1\\
  -B_n^2 & B_n^1 & 0
\end{bmatrix}\,.
\]

Since the determinant of \(\left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)\) is simply \(1+\left(\frac{1}{2}\frac{q\Delta t}{m} B_n^1\right)^2 + \left(\frac{1}{2}\frac{q\Delta t}{m} B_n^2\right)^2+ \left(\frac{1}{2}\frac{q\Delta t}{m} B_n^3\right)^2 \neq 0\) it has an inverse, so we can further reduce~\cref{eq:boris-matrix-2} to

\begin{equation}
  \vb{v_{n+\frac{1}{2}}} =\left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)^{-1} \left( I_3 - \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right) \vb{v_{n-\frac{1}{2}}} + \frac{q\Delta t}{m} \left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)^{-1} \vb{E_n}\,.
\end{equation}
For convenience we will make the notation

\begin{equation}
  R \equiv \left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)^{-1} \left( I_3 - \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)\,,
\end{equation}
so the system of equations for our scheme is now

\begin{subequations}
  \begin{align}
    \vb{r_{n+1}} = \vb{r_n} + \Delta t R \vb{v_{n-\frac{1}{2}}} + \frac{q\Delta t^2}{m} \left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)^{-1} \vb{E_n}\\
    \vb{v_{n+\frac{1}{2}}} = R \vb{v_{n-\frac{1}{2}}} + \frac{q\Delta t}{m} \left( I_3 + \frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n} \right)^{-1} \vb{E_n}\,.
  \end{align}
\end{subequations}
The Jacobi matrix of this scheme is

\begin{equation}
\label{eq:jacobian}
  \pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})} =
  \begin{bmatrix}
    \pdv{\vb{r_{n+1}}}{\vb{r_n}} & \pdv{\vb{r_{n+1}}}{v_{n-\frac{1}{2}}}\\
    \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & \pdv{\vb{v_{n+\frac{1}{2}}}}{v_{n-\frac{1}{2}}}
  \end{bmatrix} =
  \begin{bmatrix}
    I_3 + \Delta t \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & R \Delta t\\
    \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & R
  \end{bmatrix}\,.
\end{equation}

We now have to check if

\begin{equation}
  \left[\pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})}\right]^T J \pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})} = J\,.
\end{equation}
Under the notation

\begin{equation}
  \pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})} =
  \begin{bmatrix}
    A_1 & A_2\\
    A_3 & A_4
  \end{bmatrix}\,,
\end{equation}
this identity can be expressed as

\begin{equation*}
  \left[\pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})}\right]^T
  \begin{bmatrix}
    0 & I_3\\
    -I_3 & 0
  \end{bmatrix}
  \pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})} =
  \begin{bmatrix}
    A_1^T & A_3^T\\
    A_2^T & A_4^T
  \end{bmatrix}
  \begin{bmatrix}
    0 & I_3\\
    -I_3 & 0
  \end{bmatrix}
  \begin{bmatrix}
    A_1 & A_2\\
    A_3 & A_4
  \end{bmatrix} =
\end{equation*}

\begin{equation*}
  = \begin{bmatrix}
    A_1^T & A_3^T\\
    A_2^T & A_4^T
  \end{bmatrix}
  \begin{bmatrix}
    A_3 & A_4\\
    -A_1 & -A_2
  \end{bmatrix} =
  \begin{bmatrix}
    A_1^T A_3 - A_3^T A_1 & A_1^T A_4 - A_3^T A_2\\
    A_2^T A_3 - A_4^T A_1 & A_2^T A_4 - A_4^T A_2
  \end{bmatrix} =
  \begin{bmatrix}
    0 & I_3\\
    -I_3 & 0
  \end{bmatrix}\,,
\end{equation*}
which leads to the following system of matrix equations

\begin{subequations}
  \begin{align}
    \left(A_1^T A_3\right)^T = A_1^T A_3\\
    \left(A_2^T A_4\right)^T = A_2^T A_4\\
    \label{eq:111}
    \left(A_1^T A_4 - A_3^T A_2\right)^T = A_1^T A_4 - A_3^T A_2 = I_3\,.
  \end{align}
\end{subequations}
It is quite impossible to work with these equations, since they can be written for any electromagnetic fields. However, if we want to show that the Boris push is not symplectic, a particular example that doesn't satisfy these identities is enough. Indeed, if we make the choice that the electric and magnetic fields do not depend on position, then \(\pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} = 0\), so the \(A\) matrices become

\begin{subequations}
  \begin{align}
    A_1 = I_3\\
    A_2 = R \Delta t\\
    A_3 = 0\\
    A_4 = R\,.
  \end{align}
\end{subequations}
With this choice,~\cref{eq:111} leads to the obvious contradiction

\begin{equation}
  A_1^T A_4 - A_3^T A_2 = R = I_3\,,
\end{equation}
so the Boris push is not symplectic. But is it area-preserving? To see this we only have to compute the determinant of the Jacobian~(\ref{eq:jacobian}) and see if it is equal to 1.

\begin{equation}
  \abs{\pdv{(\vb{r_{n+1}}, \vb{v_{n+\frac{1}{2}}})}{(\vb{r_n}, \vb{v_{n-\frac{1}{2}}})}} =
  \begin{vmatrix}
    I_3 + \Delta t \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & R \Delta t\\
    \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & R
  \end{vmatrix}
  \overset{row1 - \Delta t\, row2}{\scalebox{7}[1]{=}}
  \begin{vmatrix}
    I_3 & 0_3\\
    \pdv{\vb{v_{n+\frac{1}{2}}}}{\vb{r_n}} & R
  \end{vmatrix} = \abs{R}\,.
\end{equation}
Let us denote \(\frac{1}{2}\frac{q\Delta t}{m} \vb{\hat{B}_n}\) by \(\Omega\). By direct calculation we can show that

\begin{equation}
  \det(I_3 + \Omega) = \det(I_3 - \Omega) = 1+\left(\frac{1}{2}\frac{q\Delta t}{m} B_n^1\right)^2 + \left(\frac{1}{2}\frac{q\Delta t}{m} B_n^2\right)^2+ \left(\frac{1}{2}\frac{q\Delta t}{m} B_n^3\right)^2 \,,
\end{equation}
such that

\begin{equation}
  \abs{R} = \det((I_3 + \Omega)^{-1} (I_3 - \Omega)) = \det((I_3 + \Omega)^{-1}) \det(I_3 - \Omega) = \frac{\det(I_3 - \Omega)}{\det(I_3 + \Omega)} = 1\,.
\end{equation}
This concludes the proof that the Boris push is area-preserving.

We will not bother to study also the relativistic algorithm since it is pretty much the same thing with a few changes. In the article by~\cite{zhangVolumepreservingAlgorithmSecular2015}, the authors claim to provide a \textit{new} particle pusher that is volume preserving (since, as they say, the relativistic Boris push is not), but it turns out that their original scheme is exactly that of Boris. Nonetheless, the article proves area-preservance for the relativistic Boris push.

\end{document}
